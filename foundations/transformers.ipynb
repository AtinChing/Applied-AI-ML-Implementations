{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfomers\n",
    "- Transformers are perhaps one of the most special, impactful and important creations in AI/Computer Science of **all time**.\n",
    "- Transformer models are used to solve all kinds of tasks across different modalities, including natural language processing (NLP), computer vision, audio processing, and more.\n",
    "\n",
    "### Hugging Face Transformers Library\n",
    "\n",
    "The **Hugging Face Transformers** library is the most important and widely-used library for working with transformer models in the AI/ML ecosystem.\n",
    "\n",
    "### What is it?\n",
    "- A comprehensive Python library that provides easy access to thousands of pre-trained transformer models\n",
    "- Supports all major transformer architectures: BERT, GPT, T5, RoBERTa, DistilBERT, and many more\n",
    "- Provides a unified, consistent API regardless of the underlying model architecture\n",
    "- Includes tools for fine-tuning, training from scratch, and deploying models to production\n",
    "\n",
    "### Why it's significant\n",
    "The library democratized AI by making state-of-the-art transformer models accessible to developers, researchers, and companies worldwide. It created a standardized interface that works across different model families and tasks, building the largest model hub with 100,000+ pre-trained models shared by the community. This massive ecosystem is now used by thousands of companies in real-world applications.\n",
    "\n",
    "### The Pipeline Function - The Game Changer\n",
    "\n",
    "- The `pipeline()` function is the most simple object in the transformers library, yet perhaps the most revolutionary feature - it's like having a \"one-click\" solution for AI tasks. It handles tokenization, model loading, and post-processing automatically, supporting 20+ different tasks (classification, generation, translation, summarization, etc.) with zero configuration needed.\n",
    "- You can think of it as something that connects a model with its necessary preprocessing and postprocessing steps. This lets us directly input any text and get an intelligible answer.\n",
    "- Below I will show you an example of sentiment analysis using the pipeline function, on our own inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from -r transformers_requirements.txt (line 1)) (0.8.1)\n",
      "Requirement already satisfied: torch in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from -r transformers_requirements.txt (line 3)) (2.7.1)\n",
      "Collecting matplotlib (from -r transformers_requirements.txt (line 4))\n",
      "  Using cached matplotlib-3.10.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting seaborn (from -r transformers_requirements.txt (line 5))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from -r transformers_requirements.txt (line 2)) (4.53.0)\n",
      "Requirement already satisfied: filelock in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (6.31.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from torch->-r transformers_requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from torch->-r transformers_requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from torch->-r transformers_requirements.txt (line 3)) (3.1.6)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r transformers_requirements.txt (line 4))\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r transformers_requirements.txt (line 4))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r transformers_requirements.txt (line 4))\n",
      "  Using cached fonttools-4.58.4-cp310-cp310-macosx_10_9_universal2.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r transformers_requirements.txt (line 4))\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib->-r transformers_requirements.txt (line 4))\n",
      "  Using cached pillow-11.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->-r transformers_requirements.txt (line 4))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from matplotlib->-r transformers_requirements.txt (line 4)) (2.9.0.post0)\n",
      "Collecting pandas>=1.2 (from seaborn->-r transformers_requirements.txt (line 5))\n",
      "  Using cached pandas-2.3.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn->-r transformers_requirements.txt (line 5))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn->-r transformers_requirements.txt (line 5))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->-r transformers_requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->-r transformers_requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from jinja2->torch->-r transformers_requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from requests->transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from requests->transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from requests->transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages (from requests->transformers[sentencepiece]->-r transformers_requirements.txt (line 2)) (2025.6.15)\n",
      "Downloading matplotlib-3.10.3-cp310-cp310-macosx_11_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl (253 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.4-cp310-cp310-macosx_10_9_universal2.whl (2.7 MB)\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached pandas-2.3.0-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached pillow-11.2.1-cp310-cp310-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, seaborn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [seaborn]9/11\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pandas-2.3.0 pillow-11.2.1 pyparsing-3.2.3 pytz-2025.2 seaborn-0.13.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r transformers_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9931273460388184}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\") # there are SO many differents tasks you could name here\n",
    "# by default, a particular pretrained model that has been fine-tuned for sentiment analysis in English gets chosen\n",
    "# here, sentinment-analysis defaults to distilbert-base-uncased-finetuned-sst-2-english,\n",
    "# which is part of the BERT model lines (by Google)\n",
    "classifier(\"I'm so hungry man!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9961236119270325},\n",
       " {'label': 'POSITIVE', 'score': 0.9998375177383423}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can even do multiple outputs\n",
    "classifier(\n",
    "    [\"I'm so hungry man.\", \"I love food so much.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that the model gets downloaded and cached when you create the classifier object. Now, everytime you rerun the command, the cached model gets used instead, no need for repeated downloads.\n",
    "Here's what happens everytime you pass some text into a pipeline:\n",
    "- The text is preprocessed into a format the model can understand.\n",
    "- The preprocessed inputs are passed to the model.\n",
    "- The predictions of the model are post-processed, so you can make sense of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also worth noting the different tasks you can do with the pipeline object. Below are some examples:\n",
    "\n",
    "Text pipelines\n",
    "- text-generation: Generate text from a prompt\n",
    "- text-classification: Classify text into predefined categories\n",
    "- summarization: Create a shorter version of a text while preserving key information\n",
    "- translation: Translate text from one language to another\n",
    "- zero-shot-classification: Classify text without prior training on specific labels\n",
    "- feature-extraction: Extract vector representations of text\n",
    "\n",
    "Image pipelines\n",
    "- image-to-text: Generate text descriptions of images\n",
    "- image-classification: Identify objects in an image\n",
    "- object-detection: Locate and identify objects in images\n",
    "\n",
    "Audio pipelines\n",
    "- automatic-speech-recognition: Convert speech to text\n",
    "- audio-classification: Classify audio into categories\n",
    "- text-to-speech: Convert text to spoken audio\n",
    "\n",
    "Multimodal pipelines\n",
    "- image-text-to-text: Respond to an image based on a text prompt\n",
    "\n",
    "Now, lets try classifying texts that haven't been labelled. We're going to use something called zero-shot classification, as it allows us to specify which labels to use for classification, so we don't have to rely on pretrained models' labels. \n",
    "- (The pipeline is called zero-shot because you don’t need to fine-tune the model on your data to use it. It can directly return probability scores for any list of labels you want.)\n",
    "\n",
    "In the above example, we classified using 2 labels: positive and negative. But now I'll show you how to classify text using ANY set of labels of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': \"History isn't really a fun class\",\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.7267491817474365, 0.19325977563858032, 0.07999099045991898]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"History isn't really a fun class\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also choose a specific model for a specific task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"So today, I just feel like I need to make sure that I am getting all of my 2016 goals accomplished. \\xa0I have my goals for 2016, but I didn't get everything accomplished. \\xa0So, I want to make sure that I can see what I have accomplished.\\n\\nI need to get more into the habit of writing in my journal, I think that will help me get through a lot of things. \\xa0I know that when I feel like I am not feeling good, I can just go into my journal and take a look at what I should be doing. \\xa0It will help me see where I need to improve.\\n\\nI am going to post the 2016 goals that I have listed in this post. \\xa0I have listed the goals for each day, and will have a few goals for each week and month.\\n\\nI want to be able to see these goals, so I can see where I am and where I need to improve. \\xa0I know that if I don't see these, I will feel discouraged and will not be able to get through a lot of things.\\n\\nI want to be able to see how far I have come, so even if I didn't accomplish\"},\n",
       " {'generated_text': \"So today, I just feel like I'm being told what to do by my own government. I'm tired of the government telling me what I can do in my own home.\\n\\nThis is a scary thing.\\n\\nAnd I'm just so tired of all the BS that's going on right now.\\n\\nI thought we were living in a world where we could be free of government now. After all, we've been over this before. We've had our rights and freedoms. We've had our rights and freedoms taken away. And now, we're being told what to do by the government.\\n\\nI know this isn't a new concept. I've been telling my kids this for years. It's been on the news. It's on the radio. It's being taught in our schools. And I'm tired of it.\\n\\nI want to be free of government. I want to be free of this government tyranny. I want to be free of the government that tells me what to do.\\n\\nI want to be free of this government that is telling me what to do.\\n\\nI want to be free of this government that tells me what to do.\\n\\nI want to be free of this government that tells me what to do.\\n\\nI\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\") # all these models names\n",
    "# are names directly from the hugging face hub's website. You can plug in ANY model from their hub.\n",
    "# It includes all possible basic models too, that you could ever think of.\n",
    "\n",
    "# This is text generation, where you just provide some prompt, and the model auto-completes it by generating the remaining text.\n",
    "# Similar to text predictions you see on your phone.\n",
    "# Text generation is random, and it is unlikely you will get the exact same responses every time.\n",
    "\n",
    "generator(\n",
    "    \"So today, I just feel like\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are SO many other tasks and examples I could show you, that I will not be exhaustively going over them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data from multiple sources\n",
    "One powerful application of Transformer models is their ability to combine and process data from multiple sources. This is especially useful when you need to:\n",
    "\n",
    "- Search across multiple databases or repositories\n",
    "- Consolidate information from different formats (text, images, audio)\n",
    "- Create a unified view of related information\n",
    "\n",
    "For example, you could build a system that:\n",
    "- Searches for information across databases in multiple modalities like text and image.\n",
    "- Combines results from different sources into a single coherent response. For example, from an audio file and text description.\n",
    "- Presents the most relevant information from a database of documents and metadata.\n",
    "\n",
    "This is an import aspect of transformers, and is just something worth noting.\n",
    "Next, we're going to get into the really good stuff, the nitty-gritty, how transformers ACTUALLY work, whats goes on in the inside, and transformer model architecture, in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Architecture\n",
    "- Transformer architecture is mainly composed of 2 blocks/layers/models:\n",
    "  - Encoder layer (left): The encoder receives an input and builds a representation of it (its features). This means that the model is optimized to acquire understanding from the input.\n",
    "  - Decoder (right): The decoder uses the encoder’s representation (features) along with other inputs to generate a target sequence. This means that the model is optimized for generating outputs. \n",
    "- Here's an image for visualisation\n",
    "\n",
    "![Transformer Architecture Visualisation](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_blocks-dark.svg)\n",
    "- Each of these parts can be used independently too, depending on the task:\n",
    "  - Encoder-only models: Good for tasks that require understanding of the input, such as sentence classification and named entity recognition.\n",
    "  - Decoder-only models: Good for generative tasks such as text generation.\n",
    "  - Encoder-decoder models or sequence-to-sequence models: Good for generative tasks that require an input, such as translation or summarization (what you see with pure ChatGPT).\n",
    "- Another key aspect of Transformer models are **Attention layers**.\n",
    "  - By the way, the transformer architecture was introduced in a Google paper titled \"Attention is All You Need\". Says a lot.\n",
    "-  This layer tells the model to pay attention **specifically** to certain parts of the data (e.g. with LLMs, that would be words in the sentence) that you passed it (and more or less ignore the others), when dealing with the representation of each piece of data (word). \n",
    "    - Here's an example: imagine you have to translate \"You like this house\" from English to French. The translation model will need to look at \"you\" to get the proper translation for \"like\", because in French, the word \"like\" is written differently depending on the subject. But, the rest of the sentence is not useful for the translation of \"like\".\n",
    "    - In the same way, when translating “this” the model will also need to pay attention to the word \"house\", because “this” translates differently, depending on if the noun is masculine or feminine. Again, the other words in the sentence will not matter for the translation of “house”. \n",
    "    - With more complex sentences (and more complex grammar rules), the model would need to pay special attention to words that might appear farther away in the sentence to properly translate each word.\n",
    "    - This same concept applies to ANY task at ANY scale associated with natural language: a word by itself has a meaning, but that meaning is deeply affected by the context, which can be any other word (or words) before or after the word being studied.\n",
    "    - Here's a code visualization and application of our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atin5551/Documents/GitHub/Applied AI ML Implementations/.venv/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 'You like this house'\n",
      "Tokens: ['▁You', '▁like', '▁this', '▁house', '</s>']\n",
      "Attention tensor shape: torch.Size([1, 8, 5, 5])\n",
      "Filtered tokens (no special tokens): ['▁You', '▁like', '▁this', '▁house']\n",
      "Filtered attention shape: torch.Size([4, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpretation Guide:\n",
      "--------------------------------------------------\n",
      "This heatmap shows how much each word (row) attends to each word (column) during encoding.\n",
      "Higher values (darker blue) indicate stronger attention connections.\n",
      "For example, 'like' may attend strongly to 'You' for proper French conjugation,\n",
      "and 'this' may attend to 'house' for gender agreement in French.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention Analysis:\n",
      "--------------------------------------------------\n",
      "'▁You' → '▁like': 0.426\n",
      "'▁like' → '▁this': 0.204\n",
      "'▁this' → '▁like': 0.229\n",
      "'▁this' → '▁house': 0.267\n",
      "\n",
      "Translation: Tu aimes cette maison\n",
      "\n",
      "Self-attention scores:\n",
      "'▁You' self-attention: 0.202\n",
      "'▁like' self-attention: 0.223\n",
      "'▁this' self-attention: 0.225\n",
      "'▁house' self-attention: 0.226\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load the pretrained English-to-French translation model\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(\n",
    "    model_name,\n",
    "    attn_implementation=\"eager\",  # Use eager attention implementation\n",
    "    output_attentions=True        # Enable attention outputs\n",
    ")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"You like this house\"\n",
    "print(f\"Input sentence: '{sentence}'\")\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# Get token strings for visualization (excluding special tokens)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print(f\"Tokens: {tokens}\")\n",
    "\n",
    "# Forward pass with attention outputs - use encoder only\n",
    "with torch.no_grad():\n",
    "    # Get encoder outputs only to avoid decoder issues\n",
    "    encoder_outputs = model.get_encoder()(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=inputs.get(\"attention_mask\"),\n",
    "        output_attentions=True,\n",
    "        return_dict=True\n",
    "    )\n",
    "\n",
    "# Extract encoder self-attention weights from the last layer\n",
    "encoder_attentions = encoder_outputs.attentions  # Tuple of attention weights for each layer\n",
    "last_layer_attention = encoder_attentions[-1]    # Shape: (batch_size, num_heads, seq_len, seq_len)\n",
    "\n",
    "print(f\"Attention tensor shape: {last_layer_attention.shape}\")\n",
    "\n",
    "# Average over attention heads\n",
    "attention_weights = last_layer_attention.mean(dim=1)  # Shape: (batch_size, seq_len, seq_len)\n",
    "attention_weights = attention_weights.squeeze(0)      # Remove batch dimension\n",
    "\n",
    "# Identify special tokens to exclude\n",
    "special_tokens = [\"<pad>\", \"</s>\", \"<s>\", \"<unk>\"]\n",
    "non_special_indices = [i for i, token in enumerate(tokens) if token not in special_tokens]\n",
    "\n",
    "# Filter out special tokens\n",
    "filtered_tokens = [tokens[i] for i in non_special_indices]\n",
    "filtered_attention = attention_weights[non_special_indices][:, non_special_indices]\n",
    "\n",
    "print(f\"Filtered tokens (no special tokens): {filtered_tokens}\")\n",
    "print(f\"Filtered attention shape: {filtered_attention.shape}\")\n",
    "\n",
    "# Create the attention heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    filtered_attention.numpy(),\n",
    "    xticklabels=filtered_tokens,\n",
    "    yticklabels=filtered_tokens,\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    fmt=\".3f\",\n",
    "    cbar_kws={\"label\": \"Attention Weight\"}\n",
    ")\n",
    "\n",
    "plt.title(\"Encoder Self-Attention Heatmap\\nEnglish-to-French Translation: 'You like this house'\")\n",
    "plt.xlabel(\"Attending TO (Keys)\")\n",
    "plt.ylabel(\"Attending FROM (Queries)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print explanation as separate section after the plot\n",
    "print(\"\\nInterpretation Guide:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"This heatmap shows how much each word (row) attends to each word (column) during encoding.\")\n",
    "print(\"Higher values (darker blue) indicate stronger attention connections.\")\n",
    "print(\"For example, 'like' may attend strongly to 'You' for proper French conjugation,\")\n",
    "print(\"and 'this' may attend to 'house' for gender agreement in French.\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some analysis of the attention patterns\n",
    "print(\"\\nAttention Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Find the strongest attention connections\n",
    "for i, source_word in enumerate(filtered_tokens):\n",
    "    for j, target_word in enumerate(filtered_tokens):\n",
    "        if i != j:  # Skip self-attention\n",
    "            attention_score = filtered_attention[i, j].item()\n",
    "            if attention_score > 0.2:  # Threshold for \"strong\" attention\n",
    "                print(f\"'{source_word}' → '{target_word}': {attention_score:.3f}\")\n",
    "\n",
    "# Get actual translation for comparison (separate forward pass)\n",
    "with torch.no_grad():\n",
    "    translation_outputs = model.generate(input_ids, max_length=50, num_beams=1, do_sample=False)\n",
    "    translation = tokenizer.decode(translation_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"\\nTranslation: {translation}\")\n",
    "\n",
    "# Show self-attention scores (diagonal)\n",
    "print(f\"\\nSelf-attention scores:\")\n",
    "for i, word in enumerate(filtered_tokens):\n",
    "    self_attention = filtered_attention[i, i].item()\n",
    "    print(f\"'{word}' self-attention: {self_attention:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Don't worry too much if you don't understand all the code just yet).\n",
    "- In the image above, we visualize the self-attention matrix from the encoder of a MarianMT model translating the English sentence “You like this house” into French. Here’s how to interpret it:\n",
    "-\tY-axis (Query): The word that is currently being processed by the model — i.e., which word is paying attention.\n",
    "-\tX-axis (Key): The potential context words that the query word is attending to.\n",
    "-\tColor intensity: The darker the blue, the stronger the attention weight between those two words.\n",
    "    -\t**As you can see**, “you” attends strongly to “like”, due to the reason we spoke about earlier, that the French conjugation of “like” (aimer) depends on the subject (“you” → tu or vous).\n",
    "    -\tSimilarly, **as we said**, “this” attends most to “house”, likely to determine the correct gendered demonstrative (e.g., cette maison for a feminine noun).\n",
    "    - In fact, \"you\" attending to \"like\", and \"this\" attending to \"house\" are the **darkest** (highest attention weight) pairs of words on there in the self-attention matrix graphic! That's no coincidence!\n",
    "-\tThe values inside each cell represent the attention score, i.e., how much focus the model places on that relationship during encoding.\n",
    "This map reflects how context-sensitive understanding is built into translation — and how the attention mechanism lets the model dynamically adjust focus based on linguistic relationships.\n",
    "\n",
    "- In short, a row shows which tokens a particular word is focusing on.\n",
    "\n",
    "- Now that you hopefully have an idea of what attention layers are, lets look at the original transformer architecture:\n",
    "  - Original transformer architecture was designed for translation.\n",
    "  - During training, the encoder receives inputs (sentences) in a certain language, while the decoder receives the same, matching sentences in the desired target language. \n",
    "  - In the encoder, the attention layers can use all the words (process the vectorized values of all the words at once) in a sentence (since, as we just saw, the translation of a given word can be dependent on anything within the REST of the sentence). \n",
    "    - Each token (say, “like”) is allowed to “look at” all other tokens in the sentence \n",
    "      - Note: In the attention visualization, you’ll see terms like “attention between words”, but under the hood, the model is actually working with tokens — chunks of text that are processed numerically. Don’t worry if you haven’t seen this term yet — we’ll formally explain what a token is and how words get converted into tokens and embeddings in the next notebook.\n",
    "    - It calculates attention scores between itself and all others — not just those before or after it.\n",
    "    - This helps it build a context-rich representation of itself.\n",
    "    - So when the encoder processes \"like\", it doesn’t do so blindly — it considers “you”, “this”, and “house” simultaneously.\n",
    "  - The decoder, however, works sequentially (as in, it works step-by-step, generating 1 word at a time (like \"Tu\", then \"aimes\" and so on)) and can only pay attention to the words in the sentence that it has already translated (so, only the words before the word currently being generated). \n",
    "    - For example, when we have predicted the first three words of the translated target, we give them to the decoder which then uses all the inputs of the encoder to try to predict the fourth word.\n",
    "    - This process of only looking at the previously generated words at each step is called causal/auto-regressive attention.\n",
    "  - To speed things up during training (when the model has access to target sentences), the decoder is fed the whole target, but it is not allowed to use future words (if it had access to the word at position 2 when trying to predict the word at position 2, the problem would not be very hard!).\n",
    "    - By giving the decoder the full target sentence but masking out the future tokens, you allow the model to compute all the outputs in parallel (just like the encoder does), rather than having to wait and generate one at a time. \n",
    "    - This drastically reduces training time, because the computation is parallelized instead of sequential.\n",
    "  - For instance, when trying to predict the fourth word, the attention layer will only have access to the words in positions 1 to 3, because tokens 3 to the last token will be masked out.\n",
    "  - Here's a visualisation of the original Transformer architecture, with the encoder on the left and the decoder on the right:\n",
    "\n",
    "![Original Transformer Architecture Visualisation](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers-dark.svg)\n",
    "\n",
    "  - Note that the first attention layer in a decoder block pays attention to all (past) inputs to the decoder.\n",
    "  - The second attention layer uses the output of the encoder and all info passed forward from the 1st layer. It can thus access the whole input sentence, as well as the output generated so far, to best predict the current word.\n",
    "    - This is very useful as different languages can have grammatical rules that put the words in different orders, or some context provided later in the sentence may be helpful to determine the best translation of a given word.\n",
    "\t-\tThere is also the attention mask, which plays an important role during training and inference.\n",
    "  - When working with batches of sentences, not all sentences are the same length — some are shorter, and some are longer. To fit them into a uniform shape (e.g., a matrix), we pad the shorter sentences with special “padding” tokens so that all sequences match the length of the longest one.\n",
    "\t-\tHowever, these padding tokens don’t carry any real information, and we don’t want the model to waste attention on them.\n",
    "  - This is where the attention mask comes in: it tells the model which tokens are real and should be attended to, and which ones are just padding and should be ignored.\n",
    "  - Think of it like giving the model a blindfold for certain tokens — “Don’t look at these, they aren’t part of the actual sentence.”\n",
    "  - Here's a visualisation:\n",
    "\n",
    "  ![Padded sequence with attention mask matrix](padding.png)\n",
    "\n",
    "  - Hopefully, this gave you a solid mental model of how the original Transformer architecture works — particularly the encoder-decoder setup and how attention mechanisms shape language understanding and generation. We covered this not just for historical context, but because these components (like self-attention, masking, and encoder-decoder flows) form the foundation of nearly all modern Transformer-based models. \n",
    "    - Understanding them now will make it much easier to grasp variants like GPT, BERT, or T5, and to debug, fine-tune, or even build your own architectures later on.\n",
    "  #### Architectures and checkpoints\n",
    "  - This is terminology that is important to know for now and later. You’ll see mentions of architectures and checkpoints as well as models. These terms all have slightly different meanings:\n",
    "    - **Architecture**: This is the skeleton of the model — the definition of each layer and each operation that happens within the model.\n",
    "    - **Checkpoints**: These are the weights that will be loaded in a given architecture.\n",
    "    - **Model**: This is an umbrella term that isn’t as precise as “architecture” or “checkpoint\": it can mean both. This repo will specify architecture or checkpoint when it matters to reduce ambiguity.\n",
    "    - Example: BERT is an architecture while bert-base-cased, a set of weights trained by the Google team for the first release of BERT, is a checkpoint. However, one can say “the BERT model” and “the bert-base-cased model.”\n",
    "    - GPT-2 → Architecture, while gpt2, gpt2-medium, gpt2-large → Checkpoints trained on WebText\n",
    "\t  - GPT-NeoX → Architecture, while EleutherAI/gpt-neox-20b → Checkpoint trained by EleutherAI\n",
    "\t  - T5 → Architecture while t5-small, t5-base, t5-3b → Different checkpoints (varying sizes)\n",
    "\t  - GPT-4o → Architecture while gpt-4o (OpenAI API) → A specific checkpoint exposed via OpenAI’s infrastructure\n",
    "\n",
    "\n",
    "### A Note on GPT: Decoder-Only Transformers\n",
    "\n",
    "I wanted to include this part to help deepen your understanding of transformers and more specifically their **applications** (especially with decoders) even further, and especially by relating it to an example highly relevant to modern AI usage and something that you likely relate to and is a massive presence in your life: ChatGPT.\n",
    "\n",
    "The original **GPT architecture** (Generative Pretrained Transformer), first introduced in the GPT-1 paper by OpenAI, was designed as a **decoder-only Transformer**. This means it was built purely for **text generation**, without an encoder component.\n",
    "\n",
    "#### Key Features of GPT:\n",
    "- **Decoder-only**: There is no encoder. All input is handled directly by the decoder stack.\n",
    "- **Causal (unidirectional) attention**: Each token can only attend to tokens **before it** — not future tokens.\n",
    "- **Trained with a next-token prediction objective**: The model learns to predict the next word given all previous words in the sequence.\n",
    "- **Cannot accept encoded input**: Unlike encoder-decoder models (e.g., T5 or translation models), GPT does **not** take in a separately encoded source sentence.\n",
    "- Example: How GPT Works\n",
    "\n",
    "  - If you give GPT the prompt:  \n",
    "  - `\"The capital of France is\"`  \n",
    "  - It will continue the sentence — `\"Paris.\"` — using its internal understanding of the language.\n",
    "  - It doesn’t “encode” the input and then “decode” a response — the model **generates directly** using the same decoder layers throughout.\n",
    "\n",
    "##### But what about ChatGPT and complex prompts?\n",
    "\n",
    "Even though models like GPT-3.5 and GPT-4 are still decoder-only, clever techniques such as:\n",
    "- prompt formatting,\n",
    "- system/user roles,\n",
    "- fine-tuning on dialogue datasets, and\n",
    "- embedding-based retrieval\n",
    "\n",
    "allow them to **simulate** more complex input-output behaviors (like reasoning, question answering, or summarization). But under the hood, it's still a decoder-only model generating one token at a time.\n",
    "\n",
    "To make this make sense in your head, heres a specific example:\n",
    "- If a user types into ChatGPT: \"Can you help me with understanding matrix multiplication?\"\n",
    "- The ChatGPT, a decoder model, actually sees something along the lines of...\n",
    "```\n",
    "User: Okay so if this is the input (this message i am sending right now) what are you seeing?\n",
    "Assistant:\n",
    "```\n",
    "- ...due to prompt engineering/system refinement that OpenAI have done to make their product, ChatGPT, as effective as possible.\n",
    "- At this point, the model’s job is to continue this sequence, one token at a time, in a way that best fits the pattern it has seen in its training data.\n",
    "- It has no separate “input” section and no separate “output” mechanism. It’s just a single text sequence that it’s trying to complete.\n",
    "- So when you ask a question, it doesn’t “think” in terms of “processing the question” and “giving an answer” — it just generates the most likely next few tokens that fit the format of an assistant replying to a user question.\n",
    "\n",
    "⸻\n",
    "\n",
    "#### Why didn’t OpenAI just use encoder-decoder models for GPT?\n",
    "\n",
    "Because decoder-only models are **simpler, faster**, and **sufficiently powerful** — *if* you train them right and prompt them well.\n",
    "\n",
    "Let’s break this down:\n",
    "\n",
    "| Feature | Encoder-Decoder (e.g., T5) | Decoder-Only (e.g., GPT) |\n",
    "|--------|-----------------------------|---------------------------|\n",
    "| **Architecture** | Two parts: encoder reads input, decoder writes output | One part: decoder just continues text |\n",
    "| **Pros** | Clean input/output separation, good for translation and QA | Simpler, more parallelizable, faster |\n",
    "| **Training** | Needs labeled input-output pairs | Can be trained on raw text |\n",
    "| **Use cases** | Translation, summarization, question answering | Chatbots, code generation, story writing |\n",
    "\n",
    "So yes — encoder-decoder could *in theory* give more structured handling of “questions vs answers.”  \n",
    "But decoder-only:\n",
    "- Needs less compute (only one block)\n",
    "- Trains on larger unsupervised corpora\n",
    "- Has proven *shockingly capable* with few-shot prompting\n",
    "- Avoids complexity of managing two towers (encoder + decoder)\n",
    "\n",
    "> ⚠️ GPT-style prompting is *not a hack* — it’s a **design tradeoff**. They picked “scalable + general-purpose” over “structured + supervised.”\n",
    "\n",
    "This decision ultimately helped power the generality and versatility that made ChatGPT so widespread.\n",
    "\n",
    "- **Note**: you may have heard of \"thinking LLMs\". We will go over these in detail in the ```llms/``` section of this project. For now, all that is worth mentioning is that they are **NOT** the same as encoder-decoder models like T5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How transformers solve their tasks\n",
    "- Now, we will delve into specific transformer architectural variants, and how they solve their respective, specific tasks. Before we do this however, its important to understand that most tasks follow a similar pattern: input data is processed through a model, and the output is interpreted for a specific task. The differences lie in how the data is prepared, what model architecture variant is used, and how the output is processed.\n",
    "- To explain how tasks are solved, we’ll walk through what goes on inside the model to output useful predictions. We’ll cover the following models and their corresponding tasks:\n",
    "\n",
    "  - Wav2Vec2 for audio classification and automatic speech recognition (ASR)\n",
    "  - Vision Transformer (ViT) and ConvNeXT for image classification\n",
    "  - DETR for object detection\n",
    "  - Mask2Former for image segmentation\n",
    "  - GLPN for depth estimation\n",
    "  - BERT for NLP tasks like text classification, token classification and question answering that use an encoder\n",
    "  - GPT2 for NLP tasks like text generation that use a decoder\n",
    "  - BART for NLP tasks like summarization and translation that use an encoder-decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Language models, and the most famous examples:\n",
    "- All the popular Transformer models (GPT, BERT, T5, etc.) have been trained as language models. \n",
    "- Language models are just models that have been trained on large amounts of raw text in a self-supervised fashion.\n",
    "- They are the heart of modern NLP.\n",
    "- (Self-supervised learning is a type of training in which the objective is automatically computed from the inputs of the model. That means that humans are not needed to label the data!)\n",
    "- This type of model develops a statistical understanding of the patterns and relationships between words or tokens in the text it has been trained on, but it’s less useful for specific practical tasks. Because of this, the general pretrained model then goes through a process called transfer learning or fine-tuning. During this process, the model is fine-tuned in a supervised way — that is, using human-annotated labels — on a given task.\n",
    "  - Transfer learning and fine-tuning are briefly covered below.\n",
    "- An example of a task is predicting the next word in a sentence having read the n previous words. This is called causal language modeling because the output depends on the past and present inputs, but not the future ones.\n",
    "- Example below:\n",
    "\n",
    "![Causal language modeling visualization](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling-dark.svg)\n",
    "\n",
    "- Additionally, the general strategy to achieve better performance is by increasing the models’ sizes as well as the amount of data they are pretrained on.\n",
    "- Unfortunately, training a model, especially a large one, requires a large amount of data. This becomes very costly in terms of time and compute resources.\n",
    "- This means sharing models/resources is very efficient and optimal, because it saves time, potentially money, and just overall resources for everyone.\n",
    "- We will go over examples in more detail later.\n",
    "\n",
    "#### How language models work\n",
    "- Language models work by being trained to predict the probability of a word given the context of surrounding words. This gives them a foundational understanding of language that can generalize to other tasks.\n",
    "\n",
    "- There are two main approaches for training a transformer model:\n",
    "\n",
    "- **Masked language modeling (MLM):** Used by encoder models like BERT, this approach randomly masks some tokens in the input and trains the model to predict the original tokens based on the surrounding context. This allows the model to learn bidirectional context (looking at words both before and after the masked word).\n",
    "\n",
    "- **Causal language modeling (CLM):** Used by decoder models like GPT, this approach predicts the next token based on all previous tokens in the sequence. The model can only use context from the left (previous tokens) to predict the next token.\n",
    "\n",
    "- Once again, lets briefly go over the **types** of language models\n",
    "\n",
    "### Types of language models\n",
    "- In the Transformers library, language models generally fall into three architectural categories:\n",
    "\n",
    "- Encoder-only models (like BERT): These models use a bidirectional approach to understand context from both directions. They’re best suited for tasks that require deep understanding of text, such as classification, named entity recognition, and question answering.\n",
    "\n",
    "- Decoder-only models (like GPT, Llama): These models process text from left to right and are particularly good at text generation tasks. They can complete sentences, write essays, or even generate code based on a prompt.\n",
    "\n",
    "- Encoder-decoder models (like T5, BART): These models combine both approaches, using an encoder to understand the input and a decoder to generate output. They excel at sequence-to-sequence tasks like translation, summarization, and question answering.\n",
    "\n",
    "- For reminder purposes, heres a visualisation: \n",
    "\n",
    "![Language Model Architecture(s) visualisation](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_architecture.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "- Initializing a model with another model's weights.\n",
    "- Essentially, you leverage the knowledge acquired by a model trained on LOTS of data on another task.\n",
    "### Pre-training\n",
    "- **Pretraining**: training a model from scratch. The weights are initially randomly initialized, and the training starts with 0 knowledge.\n",
    "  - This pretraining is usually done on very large amounts of data. Therefore, it requires a very large corpus of data, and training can take up to several weeks.\n",
    "- **Fine-tuning**: training done AFTER a model has been pretrained. To perform fine-tuning, you first need a pretrained language model, then need to perform additional training with a dataset highly specific to your task.\n",
    "  - Now, this might seem confusing. Just train your model for your final use case from the start right? Here's some reasons why you do things this way:\n",
    "  - The pretrained model was already trained on a dataset that has some similarities with the fine-tuning dataset. The fine-tuning process is thus able to take advantage of knowledge acquired by the initial model during pretraining (for instance, with NLP problems, the pretrained model will have some kind of statistical understanding of the language you are using for your task).\n",
    "  - Since the pretrained model was already trained on lots of data, the fine-tuning requires way less data to get decent results.\n",
    "  - For the same reason, the amount of time and resources needed to get good results are much lower.\n",
    "  - Fine-tuning example:\n",
    "    - You can take a pretrained model (that was thoroughly trained on the English language), and fine-tune it on the arXiv corpus, which then results in a science/research-based model.\n",
    "      - Corpus: a large and structured collection of text or speech data used for linguistic analysis and training ML models. In NLP/LLM context, it acts as the training data for our models that need to generate human language. \n",
    "      - arXiv corpus: arXiv is an archive of scholarly articles, primarily in scientific fields. So the arXiv corpus is a collection of scholarly articles available on the arXiv repository. \n",
    "    - The fine-tuning will only require a limited amount of data. The knowledge the pretrained model has acquired is “transferred,” (You’re transferring the capabilities of the pretrained model to a new domain/task using the arXiv data), hence the term transfer learning.\n",
    "- Important to note, that transfer learning **ENCOMPASSES** fine-tuning.\n",
    "- In most situations, fine-tuning revolves around retraining the last couple layers of a model, but can be applied to the whole model.  \n",
    "- Fine-tuning a model has lower time, data, financial, and environmental costs. It is also quicker and easier to iterate over different fine-tuning schemes (full fine-tuning, last-layer tuning, freezing first n-layers and training/readjusting the rest, peft, etc), as the training is less constraining (cheaper, faster, easier to experiment with) than a full pretraining.\n",
    "- This process will also achieve better results than training from scratch (unless you have lots of data), which is why you should always try to leverage a pretrained model — one as close as possible to the task you have at hand — and fine-tune it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will explore a specific model architectures and how its applied for its corresponding task. The original thought process was to go over multiple of these, but they delve into so much detail, that I've decided it would be a lot better to teach and show case them through the `llms/` section of this project.\n",
    "- Understanding which part of the Transformer architecture (encoder, decoder, or both) is best suited for a particular NLP task is key to choosing the right model. Generally, tasks requiring bidirectional context use encoders, tasks generating text use decoders, and tasks converting one sequence to another use encoder-decoders.\n",
    "  - We will go very in-depth into these 3 different types, and what they're good at and when best to use each one, later below. For now, lets take a look at text generation as an example!\n",
    "\n",
    "### Text generation\n",
    "- Text generation involves creating coherent and contextually relevant text based on a prompt or input.\n",
    "\n",
    "- GPT-2 is a decoder-only model pretrained on a large amount of text. It can generate convincing (though not always true!) text given a prompt and complete other NLP tasks like question answering despite not being explicitly trained to.\n",
    "\n",
    "![Text Generation Architecture visualisation](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gpt2_architecture.png)\n",
    "\n",
    "- GPT-2 uses byte pair encoding (BPE) to tokenize words and generate a token embedding. Positional encodings are added to the token embeddings to indicate the position of each token in the sequence. The input embeddings are passed through multiple decoder blocks to output some final hidden state. Within each decoder block, GPT-2 uses a masked self-attention layer which means GPT-2 can’t attend to future tokens. It is only allowed to attend to tokens on the left. This is different from BERT’s [mask] token because, in masked self-attention, an attention mask is used to set the score to 0 for future tokens.\n",
    "\n",
    "- The output from the decoder is passed to a language modeling head, which performs a linear transformation to convert the hidden states into logits. The label is the next token in the sequence, which are created by shifting the logits to the right by one. The cross-entropy loss is calculated between the shifted logits and the labels to output the next most likely token.\n",
    "\n",
    "- GPT-2’s pretraining objective is based entirely on causal language modeling, predicting the next word in a sequence. This makes GPT-2 especially good at tasks that involve generating text.\n",
    "\n",
    "- Later in the `LLMs/` section, I will cover causal language modeling more in-depth, and explain how to finetune DistilGPT-2 and use it for inference!\n",
    "\n",
    "#### More in-depth examples\n",
    "- I will go over each of these application examples, with each one having its own notebook, in the `LLMs/` section of this project.\n",
    "- The examples will be on:\n",
    "  - Text classification via BERT\n",
    "  - Token classification via BERT\n",
    "  - Question answering via BERT\n",
    "  - Summarization via T5\n",
    "  - Translation via T5\n",
    "  - How speech and audio recognition are handled via Whisper\n",
    "  - Computer Vision (Image classification for example) via ViT and ConvNeXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 3 architectural variants of Transformer models, and when to use each one\n",
    "#### Encoder models\n",
    "- Encoder models use only the encoder of a Transformer model. At each stage, the attention layers can access all the words in the initial sentence. These models are often characterized as having “bi-directional” attention, and are often called auto-encoding models.\n",
    "\n",
    "- The pretraining of these models usually revolves around somehow corrupting a given sentence (for instance, by masking random words in it) and tasking the model with finding or reconstructing the initial sentence.\n",
    "\n",
    "- Encoder models are best suited for tasks requiring an understanding of the full sentence, such as sentence classification, named entity recognition (and more generally word classification), and extractive question answering\n",
    "\n",
    "- As we saw earlier, encoder models like BERT excel at understanding text because they can look at the entire context in both directions. This makes them perfect for tasks where comprehension of the whole input is important.\n",
    "\n",
    "- The biggest representatives of this family of models include:\n",
    "  - BERT\n",
    "  - DistilBERT\n",
    "  - ModernBERT\n",
    "  - As you can see, this space is very dominated by BERT/Google\n",
    "\n",
    "\n",
    "#### Decoder models\n",
    "- Decoder models use only the decoder of a Transformer model. At each stage, for a given word the attention layers can only access the words positioned before it in the sentence. These models are often called auto-regressive models.\n",
    "- The pretraining of decoder models usually revolves around predicting the next word in the sentence.\n",
    "\n",
    "- These models are best suited for tasks involving text generation.\n",
    "> Decoder models like GPT are designed to generate text by predicting one token at a time. As we explored earlier, they can only see previous tokens, which makes them excellent for creative text generation but less ideal for tasks requiring bidirectional understanding.\n",
    "\n",
    "##### Representatives of this family of models include:\n",
    "\n",
    "- Hugging Face SmolLM Series\n",
    "- Meta’s Llama Series\n",
    "- Google’s Gemma Series\n",
    "- DeepSeek’s V3\n",
    "\n",
    "##### Modern LLMs\n",
    "- Most modern Large Language Models (LLMs) use the decoder-only architecture. These models have grown dramatically in size and capabilities over the past few years, with some of the largest models containing hundreds of billions of parameters.\n",
    "\n",
    "- Modern LLMs are typically trained in two phases:\n",
    "\n",
    "- Pretraining: The model learns to predict the next token on vast amounts of text data\n",
    "- Instruction tuning: The model is fine-tuned to follow instructions and generate helpful responses\n",
    "- This approach has led to models that can understand and generate human-like text across a wide range of topics and tasks.\n",
    "\n",
    "##### Key capabilities of modern LLMs\n",
    "- Modern decoder-based LLMs have demonstrated impressive capabilities:\n",
    "- Capability\tDescription\tExample\n",
    "- Text generation\tCreating coherent and contextually relevant text\tWriting essays, stories, or emails\n",
    "- Summarization\tCondensing long documents into shorter versions\tCreating executive summaries of reports\n",
    "- Translation\tConverting text between languages\tTranslating English to Spanish\n",
    "- Question answering\tProviding answers to factual questions\t“What is the capital of France?”\n",
    "- Code generation\tWriting or completing code snippets\tCreating a function based on a description\n",
    "- Reasoning\tWorking through problems step by step\tSolving math problems or logical puzzles\n",
    "- Few-shot learning\tLearning from a few examples in the prompt\tClassifying text after seeing just 2-3 examples\n",
    "- Hugging Face is a great place where you can directly play around with and test different models through convenient UI.\n",
    "\n",
    "# Sequence to Sequence models\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
