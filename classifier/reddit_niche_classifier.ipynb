{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67769b",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "Proper about me can be made later\n",
    "Classifier that classifies what niche category a certain reddit post falls into.\n",
    "\n",
    "\n",
    "### To-do/Ideas for the future.\n",
    "- Need to find/determine a workflow that cleans all the data that we scrape/get from reddit via PRAW.\n",
    "- Can use LLMs for data-augmentation as well, not just weak supervision. I.e, we can pass our actual existing reddit posts' data into an LLM to give it some ideas and show it some inspiration, and use that to get it to generate more reddit stories that are likely to be viral within a specific chosen niche of our choice.\n",
    "    - Additionally, instead of just passing good known stories into a general-purpose LLM (like Gemini or GPT-based LLMs) like we are right now, we could train or fine-tune a domain-specific LLM that is dedicated for this task (generating reddit posts within a specific niche that are likely to go viral).\n",
    "\n",
    "First, we need to collect data.\n",
    "There aren't many very good datasets, so we need to create our own.\n",
    "This will be done through data scraping via PRAW and weak supervision via a chosen LLM (I am using Gemini for this).\n",
    "\n",
    "First, scraping data via PRAW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9773d9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (7.8.1)\n",
      "Collecting pandas (from -r requirements.txt (line 2))\n",
      "  Downloading pandas-2.2.3-cp312-cp312-macosx_10_9_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: google-genai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.11.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from praw->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from praw->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from praw->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 2))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 2))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-genai->-r requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-genai->-r requirements.txt (line 3)) (2.39.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-genai->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-genai->-r requirements.txt (line 3)) (2.11.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-genai->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-genai->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-genai->-r requirements.txt (line 3)) (4.13.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 3)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 3)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 3)) (4.9.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 3)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 3)) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai->-r requirements.txt (line 3)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 3)) (0.6.1)\n",
      "Downloading pandas-2.2.3-cp312-cp312-macosx_10_9_x86_64.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install all required dependencies\n",
    "\n",
    "%pip install -r requirements.txt --user # --user flag is needed because one of the dependencies (google-genai) needs to access a script that is hidden in non-administrator environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f954a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your necessary imports\n",
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from google import genai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926c71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize reddit client session\n",
    "\n",
    "CLIENT_ID = \"0xeiOSktNDiHBw\"\n",
    "CLIENT_SECRET = \"c-bNB_P5wRjHZmaD1eaJnx0D3mlr8Q\"\n",
    "USER_AGENT = \"sestee 1.0\"\n",
    "cli = praw.Reddit(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        user_agent=USER_AGENT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98feecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a way for you to scrape posts from a subreddit of your choice.\n",
    "def scrape_popular_posts(subreddits, limit=100, sort_by=\"top\"):\n",
    "    posts = []\n",
    "\n",
    "    for sub_name in subreddits:\n",
    "        subreddit = cli.subreddit(sub_name)\n",
    "\n",
    "        if sort_by == \"top\":\n",
    "            submissions = subreddit.top(limit=limit)\n",
    "        elif sort_by == \"hot\":\n",
    "            submissions = subreddit.hot(limit=limit)\n",
    "        elif sort_by == \"new\":\n",
    "            submissions = subreddit.new(limit=limit)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid sort_by value. Use 'top', 'hot', or 'new'.\")\n",
    "\n",
    "        for post in submissions:\n",
    "            post_data = {\n",
    "                \"title\": post.title,\n",
    "                \"selftext\": post.selftext, # For reference, selftext is the ACTUAL body text of the post\n",
    "                \"subreddit\": post.subreddit.display_name,\n",
    "                \"flair\": post.link_flair_text,\n",
    "                \"score\": post.score,\n",
    "                \"num_comments\": post.num_comments,\n",
    "                \"upvote_ratio\": post.upvote_ratio,\n",
    "                \"created_utc\": post.created_utc,\n",
    "                \"id\": post.id,\n",
    "                \"url\": post.url\n",
    "            }\n",
    "            posts.append(post_data)\n",
    "\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abb67e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "selftext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "flair",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_comments",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "upvote_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "created_utc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "niche",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9f8ea8e6-286f-45ff-93cc-622b753ec57f",
       "rows": [
        [
         "0",
         "People who haven't pooped in 2019 yet, why are you still holding on to last years shit?",
         "",
         "AskReddit",
         null,
         "221998",
         "7925",
         "0.91",
         "1546376787.0",
         "ablzuq",
         "https://www.reddit.com/r/AskReddit/comments/ablzuq/people_who_havent_pooped_in_2019_yet_why_are_you/",
         null
        ],
        [
         "1",
         "How would you feel about Reddit adding 3 NSFW filters to distinguish between porn, gore, and repetitive posts asking how you would feel about Reddit adding 2 NSFW filters to distinguish between porn and gore?",
         "",
         "AskReddit",
         null,
         "217924",
         "2886",
         "0.87",
         "1611859882.0",
         "l7530r",
         "https://www.reddit.com/r/AskReddit/comments/l7530r/how_would_you_feel_about_reddit_adding_3_nsfw/",
         null
        ],
        [
         "2",
         "Would you watch a show where a billionaire CEO has to go an entire month on their lowest paid employees salary, without access to any other resources than that of the employee? What do you think would happen?",
         "",
         "AskReddit",
         null,
         "197606",
         "13327",
         "0.9",
         "1581069212.0",
         "f08dxb",
         "https://www.reddit.com/r/AskReddit/comments/f08dxb/would_you_watch_a_show_where_a_billionaire_ceo/",
         null
        ],
        [
         "3",
         "What if God came down one day and said \"It's pronounced 'Jod' then left?",
         "",
         "AskReddit",
         null,
         "195914",
         "10227",
         "0.92",
         "1600610511.0",
         "iwedc5",
         "https://www.reddit.com/r/AskReddit/comments/iwedc5/what_if_god_came_down_one_day_and_said_its/",
         null
        ],
        [
         "4",
         "How would you feel about a feature where if someone upvotes a crosspost, the original post is upvoted automatically?",
         "",
         "AskReddit",
         null,
         "186432",
         "2772",
         "0.9",
         "1572832666.0",
         "draola",
         "https://www.reddit.com/r/AskReddit/comments/draola/how_would_you_feel_about_a_feature_where_if/",
         null
        ],
        [
         "5",
         "How would you feel about a \"if you accidentally scroll to the top, you can go back to where you were,\" button for Reddit?",
         "",
         "AskReddit",
         null,
         "182987",
         "4303",
         "0.79",
         "1609883274.0",
         "kr8op6",
         "https://www.reddit.com/r/AskReddit/comments/kr8op6/how_would_you_feel_about_a_if_you_accidentally/",
         null
        ],
        [
         "6",
         "Stan Lee has passed away at 95 years old",
         "As many of you know today is day that many of us have dreaded. Stan Lee has passed away at the age of 95. He leaves behind a legacy of superheroes and stories that have touched many people's lives for decades. We wanted to make this thread to honor and remember this wonderful man, so please use it discuss his life, his work, [his cameos](https://thumbs.gfycat.com/RapidClearDungenesscrab-small.gif), etc and what they meant to you. \n\nExcelsior!\n\n-The AskReddit mods",
         "AskReddit",
         "Breaking News",
         "175369",
         "27643",
         "0.87",
         "1542052467.0",
         "9whgf4",
         "https://www.reddit.com/r/AskReddit/comments/9whgf4/stan_lee_has_passed_away_at_95_years_old/",
         null
        ],
        [
         "7",
         "Reddit, how would you feel about a law that bans radio stations from playing commercials with honking/beeping/siren noises in them?",
         "",
         "AskReddit",
         null,
         "160338",
         "6728",
         "0.85",
         "1537293678.0",
         "9gx68l",
         "https://www.reddit.com/r/AskReddit/comments/9gx68l/reddit_how_would_you_feel_about_a_law_that_bans/",
         null
        ],
        [
         "8",
         "Bill Gates said, \"I will always choose a lazy person to do a difficult job because a lazy person will find an easy way to do it.\" What's a real-life example of this?",
         "",
         "AskReddit",
         null,
         "154346",
         "14767",
         "0.93",
         "1593521622.0",
         "himsju",
         "https://www.reddit.com/r/AskReddit/comments/himsju/bill_gates_said_i_will_always_choose_a_lazy/",
         null
        ],
        [
         "9",
         "What if Earth is like one of those uncontacted tribes in South America, like the whole Galaxy knows we're here but they've agreed not to contact us until we figure it out for ourselves?",
         "",
         "AskReddit",
         null,
         "152116",
         "8568",
         "0.89",
         "1608946885.0",
         "kka536",
         "https://www.reddit.com/r/AskReddit/comments/kka536/what_if_earth_is_like_one_of_those_uncontacted/",
         null
        ],
        [
         "10",
         "Anthony Bourdain once said \"There's a guy in my head, and all he wants to do is lay in bed all day long, smoke pot, and watch old movies and cartoons. My life is a series of strategems, to avoid, and outwit that guy\". Who is \"that guy\" for you, and what do you do to avoid him?",
         "",
         "AskReddit",
         null,
         "150817",
         "10980",
         "0.92",
         "1570140030.0",
         "dcxylq",
         "https://www.reddit.com/r/AskReddit/comments/dcxylq/anthony_bourdain_once_said_theres_a_guy_in_my/",
         null
        ],
        [
         "11",
         "How is everyone enjoying Reddit while Instagram Facebook and whatsapp are all down?",
         "",
         "AskReddit",
         null,
         "148720",
         "13789",
         "0.81",
         "1633365005.0",
         "q18zrj",
         "https://www.reddit.com/r/AskReddit/comments/q18zrj/how_is_everyone_enjoying_reddit_while_instagram/",
         null
        ],
        [
         "12",
         "It's more than likely that Covid-19 will still be around at Christmas time - how are we going to explain to kids that Santa is still allowed to go into millions of houses?",
         "",
         "AskReddit",
         null,
         "145252",
         "15841",
         "0.85",
         "1596718197.0",
         "i4r81a",
         "https://www.reddit.com/r/AskReddit/comments/i4r81a/its_more_than_likely_that_covid19_will_still_be/",
         null
        ],
        [
         "13",
         "Without saying what the category is, what are your top five?",
         " ",
         "AskReddit",
         null,
         "144680",
         "25953",
         "0.94",
         "1534953056.0",
         "99eh6b",
         "https://www.reddit.com/r/AskReddit/comments/99eh6b/without_saying_what_the_category_is_what_are_your/",
         null
        ],
        [
         "14",
         "What free things online should everyone take advantage of?",
         "",
         "AskReddit",
         null,
         "141642",
         "14674",
         "0.96",
         "1576757459.0",
         "ecscwk",
         "https://www.reddit.com/r/AskReddit/comments/ecscwk/what_free_things_online_should_everyone_take/",
         null
        ],
        [
         "15",
         "With all of the negative headlines dominating the news these days, it can be difficult to spot signs of progress. What makes you optimistic about the future?",
         "",
         "AskReddit",
         null,
         "139492",
         "20920",
         "0.92",
         "1519761227.0",
         "80phz7",
         "https://www.reddit.com/r/AskReddit/comments/80phz7/with_all_of_the_negative_headlines_dominating_the/",
         null
        ],
        [
         "16",
         "Steve Irwin has you pinned down in a headlock, what cool facts does he tell the audience about you and your habitat?",
         "",
         "AskReddit",
         null,
         "137320",
         "5333",
         "0.91",
         "1599071736.0",
         "ilcknh",
         "https://www.reddit.com/r/AskReddit/comments/ilcknh/steve_irwin_has_you_pinned_down_in_a_headlock/",
         null
        ],
        [
         "17",
         "[Serious] Americans, would you be in support of putting a law in place that government officials, such as senators and the president, go without pay during shutdowns like this while other federal employees do? Why, or why not?",
         "",
         "AskReddit",
         "Serious Replies Only",
         "137171",
         "10392",
         "0.82",
         "1548092291.0",
         "aicgpz",
         "https://www.reddit.com/r/AskReddit/comments/aicgpz/serious_americans_would_you_be_in_support_of/",
         null
        ],
        [
         "18",
         "Iceland just announced that every Icelander over the age of 18 automatically become organ donors with ability to opt out. How do you feel about this?",
         "",
         "AskReddit",
         null,
         "135273",
         "15240",
         "0.79",
         "1546542743.0",
         "ac9038",
         "https://www.reddit.com/r/AskReddit/comments/ac9038/iceland_just_announced_that_every_icelander_over/",
         null
        ],
        [
         "19",
         "With Christmas 364 days away, people who already have their decorations up, why?",
         "",
         "AskReddit",
         null,
         "133687",
         "3469",
         "0.72",
         "1609004697.0",
         "kkmgzr",
         "https://www.reddit.com/r/AskReddit/comments/kkmgzr/with_christmas_364_days_away_people_who_already/",
         null
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>flair</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>niche</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>221998</td>\n",
       "      <td>7925</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.546377e+09</td>\n",
       "      <td>ablzuq</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/ab...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How would you feel about Reddit adding 3 NSFW ...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>217924</td>\n",
       "      <td>2886</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.611860e+09</td>\n",
       "      <td>l7530r</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/l7...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Would you watch a show where a billionaire CEO...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>197606</td>\n",
       "      <td>13327</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.581069e+09</td>\n",
       "      <td>f08dxb</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/f0...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What if God came down one day and said \"It's p...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>195914</td>\n",
       "      <td>10227</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.600611e+09</td>\n",
       "      <td>iwedc5</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/iw...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How would you feel about a feature where if so...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>186432</td>\n",
       "      <td>2772</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.572833e+09</td>\n",
       "      <td>draola</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/dr...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How would you feel about a \"if you accidentall...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>182987</td>\n",
       "      <td>4303</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.609883e+09</td>\n",
       "      <td>kr8op6</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/kr...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Breaking News</td>\n",
       "      <td>175369</td>\n",
       "      <td>27643</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.542052e+09</td>\n",
       "      <td>9whgf4</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/9w...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>160338</td>\n",
       "      <td>6728</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.537294e+09</td>\n",
       "      <td>9gx68l</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/9g...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bill Gates said, \"I will always choose a lazy ...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>154346</td>\n",
       "      <td>14767</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.593522e+09</td>\n",
       "      <td>himsju</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/hi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What if Earth is like one of those uncontacted...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>152116</td>\n",
       "      <td>8568</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.608947e+09</td>\n",
       "      <td>kka536</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/kk...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Anthony Bourdain once said \"There's a guy in m...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>150817</td>\n",
       "      <td>10980</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.570140e+09</td>\n",
       "      <td>dcxylq</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/dc...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How is everyone enjoying Reddit while Instagra...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>148720</td>\n",
       "      <td>13789</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.633365e+09</td>\n",
       "      <td>q18zrj</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/q1...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>It's more than likely that Covid-19 will still...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>145252</td>\n",
       "      <td>15841</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.596718e+09</td>\n",
       "      <td>i4r81a</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/i4...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Without saying what the category is, what are ...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>144680</td>\n",
       "      <td>25953</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.534953e+09</td>\n",
       "      <td>99eh6b</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/99...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What free things online should everyone take a...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>141642</td>\n",
       "      <td>14674</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.576757e+09</td>\n",
       "      <td>ecscwk</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/ec...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>With all of the negative headlines dominating ...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>139492</td>\n",
       "      <td>20920</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.519761e+09</td>\n",
       "      <td>80phz7</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/80...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Steve Irwin has you pinned down in a headlock,...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>137320</td>\n",
       "      <td>5333</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.599072e+09</td>\n",
       "      <td>ilcknh</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/il...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Serious] Americans, would you be in support o...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Serious Replies Only</td>\n",
       "      <td>137171</td>\n",
       "      <td>10392</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.548092e+09</td>\n",
       "      <td>aicgpz</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/ai...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Iceland just announced that every Icelander ov...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>135273</td>\n",
       "      <td>15240</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.546543e+09</td>\n",
       "      <td>ac9038</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/ac...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>With Christmas 364 days away, people who alrea...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>133687</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.609005e+09</td>\n",
       "      <td>kkmgzr</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/kk...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   People who haven't pooped in 2019 yet, why are...   \n",
       "1   How would you feel about Reddit adding 3 NSFW ...   \n",
       "2   Would you watch a show where a billionaire CEO...   \n",
       "3   What if God came down one day and said \"It's p...   \n",
       "4   How would you feel about a feature where if so...   \n",
       "5   How would you feel about a \"if you accidentall...   \n",
       "6            Stan Lee has passed away at 95 years old   \n",
       "7   Reddit, how would you feel about a law that ba...   \n",
       "8   Bill Gates said, \"I will always choose a lazy ...   \n",
       "9   What if Earth is like one of those uncontacted...   \n",
       "10  Anthony Bourdain once said \"There's a guy in m...   \n",
       "11  How is everyone enjoying Reddit while Instagra...   \n",
       "12  It's more than likely that Covid-19 will still...   \n",
       "13  Without saying what the category is, what are ...   \n",
       "14  What free things online should everyone take a...   \n",
       "15  With all of the negative headlines dominating ...   \n",
       "16  Steve Irwin has you pinned down in a headlock,...   \n",
       "17  [Serious] Americans, would you be in support o...   \n",
       "18  Iceland just announced that every Icelander ov...   \n",
       "19  With Christmas 364 days away, people who alrea...   \n",
       "\n",
       "                                             selftext  subreddit  \\\n",
       "0                                                      AskReddit   \n",
       "1                                                      AskReddit   \n",
       "2                                                      AskReddit   \n",
       "3                                                      AskReddit   \n",
       "4                                                      AskReddit   \n",
       "5                                                      AskReddit   \n",
       "6   As many of you know today is day that many of ...  AskReddit   \n",
       "7                                                      AskReddit   \n",
       "8                                                      AskReddit   \n",
       "9                                                      AskReddit   \n",
       "10                                                     AskReddit   \n",
       "11                                                     AskReddit   \n",
       "12                                                     AskReddit   \n",
       "13                                                     AskReddit   \n",
       "14                                                     AskReddit   \n",
       "15                                                     AskReddit   \n",
       "16                                                     AskReddit   \n",
       "17                                                     AskReddit   \n",
       "18                                                     AskReddit   \n",
       "19                                                     AskReddit   \n",
       "\n",
       "                   flair   score  num_comments  upvote_ratio   created_utc  \\\n",
       "0                   None  221998          7925          0.91  1.546377e+09   \n",
       "1                   None  217924          2886          0.87  1.611860e+09   \n",
       "2                   None  197606         13327          0.90  1.581069e+09   \n",
       "3                   None  195914         10227          0.92  1.600611e+09   \n",
       "4                   None  186432          2772          0.90  1.572833e+09   \n",
       "5                   None  182987          4303          0.79  1.609883e+09   \n",
       "6          Breaking News  175369         27643          0.87  1.542052e+09   \n",
       "7                   None  160338          6728          0.85  1.537294e+09   \n",
       "8                   None  154346         14767          0.93  1.593522e+09   \n",
       "9                   None  152116          8568          0.89  1.608947e+09   \n",
       "10                  None  150817         10980          0.92  1.570140e+09   \n",
       "11                  None  148720         13789          0.81  1.633365e+09   \n",
       "12                  None  145252         15841          0.85  1.596718e+09   \n",
       "13                  None  144680         25953          0.94  1.534953e+09   \n",
       "14                  None  141642         14674          0.96  1.576757e+09   \n",
       "15                  None  139492         20920          0.92  1.519761e+09   \n",
       "16                  None  137320          5333          0.91  1.599072e+09   \n",
       "17  Serious Replies Only  137171         10392          0.82  1.548092e+09   \n",
       "18                  None  135273         15240          0.79  1.546543e+09   \n",
       "19                  None  133687          3469          0.72  1.609005e+09   \n",
       "\n",
       "        id                                                url niche  \n",
       "0   ablzuq  https://www.reddit.com/r/AskReddit/comments/ab...  None  \n",
       "1   l7530r  https://www.reddit.com/r/AskReddit/comments/l7...  None  \n",
       "2   f08dxb  https://www.reddit.com/r/AskReddit/comments/f0...  None  \n",
       "3   iwedc5  https://www.reddit.com/r/AskReddit/comments/iw...  None  \n",
       "4   draola  https://www.reddit.com/r/AskReddit/comments/dr...  None  \n",
       "5   kr8op6  https://www.reddit.com/r/AskReddit/comments/kr...  None  \n",
       "6   9whgf4  https://www.reddit.com/r/AskReddit/comments/9w...  None  \n",
       "7   9gx68l  https://www.reddit.com/r/AskReddit/comments/9g...  None  \n",
       "8   himsju  https://www.reddit.com/r/AskReddit/comments/hi...  None  \n",
       "9   kka536  https://www.reddit.com/r/AskReddit/comments/kk...  None  \n",
       "10  dcxylq  https://www.reddit.com/r/AskReddit/comments/dc...  None  \n",
       "11  q18zrj  https://www.reddit.com/r/AskReddit/comments/q1...  None  \n",
       "12  i4r81a  https://www.reddit.com/r/AskReddit/comments/i4...  None  \n",
       "13  99eh6b  https://www.reddit.com/r/AskReddit/comments/99...  None  \n",
       "14  ecscwk  https://www.reddit.com/r/AskReddit/comments/ec...  None  \n",
       "15  80phz7  https://www.reddit.com/r/AskReddit/comments/80...  None  \n",
       "16  ilcknh  https://www.reddit.com/r/AskReddit/comments/il...  None  \n",
       "17  aicgpz  https://www.reddit.com/r/AskReddit/comments/ai...  None  \n",
       "18  ac9038  https://www.reddit.com/r/AskReddit/comments/ac...  None  \n",
       "19  kkmgzr  https://www.reddit.com/r/AskReddit/comments/kk...  None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure out what subreddits you want to scrape from\n",
    "subreddits = [\"AskReddit\", \"relationships\", \"AmItheAsshole\", \"TrueOffMyChest\", \"TIFU\"]\n",
    "# Scrape the data from the subreddits\n",
    "data = scrape_popular_posts(subreddits, limit=50, sort_by=\"top\")\n",
    "# Save the data in a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Can save the dataframe to a CSV file too!\n",
    "#df.to_csv(\"reddit_posts.csv\", index=False)\n",
    "df[\"niche\"] = None # Adding a new column to the dataframe for the niche\n",
    "# Display the first few rows of the dataframe\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406ef9f",
   "metadata": {},
   "source": [
    "Now we have a good chunk of all the data that we need. We need to clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d50082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data\n",
    "# Check and do later\n",
    "#df = df.dropna(subset=[\"selftext\", \"title\"])  # Drop rows with NaN in 'selftext' or 'title'\n",
    "#df = df[df[\"selftext\"].str.strip() != \"\"]  # Drop empty 'selftext' rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e90be",
   "metadata": {},
   "source": [
    "Now that we have our data, we will create a pipeline that allows us to label all the data entries and add a \"niche\" column via weak supervision. All entries will then be classified.\n",
    "These are the post classification categories we are planning to classify our posts into.\n",
    "\n",
    "| Label         | Description                                |\n",
    "|---------------|--------------------------------------------|\n",
    "| `advice`      | Help-seeking posts, questions, dilemmas    |\n",
    "| `story`       | Personal anecdotes with a beginning, middle, end |\n",
    "| `drama`       | High-stakes conflict, betrayal, gossip      |\n",
    "| `rant`        | Emotional venting or unfiltered frustration |\n",
    "| `humor`       | Meme-like, comedic, shitpost-style content  |\n",
    "| `informative` | Tips, how-tos, PSAs, educational content    |\n",
    "| `confession`  | Vulnerable personal reveals or identity-based confessions |\n",
    "| `unknown`     | Doesn’t fit confidently into other categories|\n",
    "\n",
    "Note: We can use the `unknown` category to find the biggest weaknesses of our LLM, and we can then possibly fine-tune our LLM later very efficiently by especially targetting its weaknesses that we've detected here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd1549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Google GenAI API client\n",
    "client = genai.Client(api_key=\"AIzaSyDSyIBzIJ9yVnXYd6sJaE7oZ0Vqnc4kEPM\")\n",
    "model = \"gemini-2.0-flash\" # There are a LOT of models to choose from. But in my experience, I feel comfortable with AND use 2.0-flash the most. Will look into 2.5 series once they go through stable release.\n",
    "template_prompt = f\"\"\"I want to train a transformer-based classifer that takes in the text of a reddit post and then classifes them into labels [personal advice, story, drama]. I only have a partial dataset for this. Can you help fill the rest for me?\n",
    "It should JUST classify the post into one niche category. The niche categories I want you to choose from are [advice, story, drama, rant, humor, informative, confession, unknown]. unknown is for when you really are not sure what category the post belongs to.\n",
    "I don't want anything else in your response aside from the 1-word niche category. I don't want any explanations or anything else. Just the 1-word niche category.\n",
    "Here is the post's data:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This above is the main template prompt that will be used with the rest of the reddit post data to create full proper prompts for every single reddit post data entry that we will classify via the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235be508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Stan Lee has passed away at 95 years old\n",
      "Body text: As many of you know today is day that many of us have dreaded. Stan Lee has passed away at the age of 95. He leaves behind a legacy of superheroes and stories that have touched many people's lives for decades. We wanted to make this thread to honor and remember this wonderful man, so please use it discuss his life, his work, [his cameos](https://thumbs.gfycat.com/RapidClearDungenesscrab-small.gif), etc and what they meant to you. \n",
      "\n",
      "Excelsior!\n",
      "\n",
      "-The AskReddit mods\n",
      "informative\n",
      "\n",
      "\n",
      "Title: Without saying what the category is, what are your top five?\n",
      "Body text:  \n",
      "advice\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m     model_niche_guess = \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(model_niche_guess + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Sleep for 5 seconds to avoid hitting googles rpm limit\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Now we need to add the model's guess to the dataframe\u001b[39;00m\n\u001b[32m     25\u001b[39m df.loc[index, \u001b[33m\"\u001b[39m\u001b[33mniche\u001b[39m\u001b[33m\"\u001b[39m] = model_niche_guess\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Pipeline to classify each one of the posts, making a call to the API and using the full prompt we made to get the response that contains the niche category we want.\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"selftext\"] == \"\":\n",
    "        #print(\"Skipping empty selftext post.\")\n",
    "        continue\n",
    "    post_data_prompt = f\"Title: {row['title']}\\nSelftext: {row['selftext']}\\n\\n\"\n",
    "    #print(\"Post that will be classified:\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Body text: {row['selftext']}\")\n",
    "    #print(\"Classifying the post...\")\n",
    "    prompt = template_prompt + post_data_prompt\n",
    "    #print(prompt)\n",
    "    response = client.models.generate_content(\n",
    "        model=model, contents=prompt\n",
    "    )\n",
    "    model_niche_guess = response.text\n",
    "    # It is possible that the model will give NO response (so response.text is None) because our prompt may contain NSFW language (outside our control). \n",
    "    # In this case we have to either set the niche to \"unknown\" or skip the post. I prefer to set it to unknown because it is a valid category still.\n",
    "    if model_niche_guess is None:\n",
    "        print(\"Model returned no response. Setting niche to 'unknown'.\")\n",
    "        model_niche_guess = \"unknown\"\n",
    "    print(model_niche_guess + \"\\n\")\n",
    "    time.sleep(5)  # Sleep for 5 seconds to avoid hitting googles rpm limit\n",
    "    # Now we need to add the model's guess to the dataframe\n",
    "    df.loc[index, \"niche\"] = model_niche_guess\n",
    "df.to_csv(\"reddit_posts_with_niches.csv\", index=False)  # Save the dataframe with the new column to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the model's guess to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5157ec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\*'\n",
      "C:\\Users\\atin5\\AppData\\Local\\Temp\\ipykernel_14792\\1628636960.py:1: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  prompt_temp = template_prompt + \"\"\"Title: TIFU by thinking a woman was a boy, and groping her boob. (kind of NSFW, though it happened at work)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates=None create_time=None response_id=None model_version='gemini-2.0-flash' prompt_feedback=GenerateContentResponsePromptFeedback(block_reason=<BlockedReason.PROHIBITED_CONTENT: 'PROHIBITED_CONTENT'>, block_reason_message=None, safety_ratings=None) usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=None, candidates_tokens_details=None, prompt_token_count=1339, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1339)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=1339, traffic_type=None) automatic_function_calling_history=[] parsed=None\n"
     ]
    }
   ],
   "source": [
    "prompt_temp = template_prompt + \"\"\"Title: TIFU by thinking a woman was a boy, and groping her boob. (kind of NSFW, though it happened at work)\n",
    "Body text: Obligatory this actually happened a little over a year ago, and throwaway because I don't want people on my main account to know what I do for a living.\n",
    "\n",
    "So, I work for the TSA, and have for a few years now. It's a good job overall. I'm underpaid, but the benefits are nice, and I get overtime when I want it.\n",
    "\n",
    "A little over a year ago, during the week leading up to Christmas, we had some really bad weather that delayed all the flights. I volunteered to stay late so that my coworkers could go home to their families. Most of the work was done anyway, so it was mostly just standing around waiting for the odd latecomer\n",
    "\n",
    "I was working the AIT (the space tube thingy), when three passengers came up together, a middle-aged man, a middle-aged woman, and a teenage boy. I figure it's a family traveling together for the holidays, and go about my work.\n",
    "\n",
    "Mom goes through, all is fine. Dad goes through, all is fine.\n",
    "\n",
    "Kid comes up, I get a good look at him. Hoodie, sweatpants, shortish hair, smooth face. I figure he's about 13, maybe 14.\n",
    "\n",
    "I hit the button, direct him to wait with me for a moment, and then gesture to the screen, which lit up on his chest area.\n",
    "\n",
    "I tell him that I have to pat that area down. He's a little nervous, I figure that because he's so young, this is probably his first time getting a pat down, but he says okay, and I start the patdown.\n",
    "\n",
    "I do the left side of the chest, and feel some moob, which catches me off guard because he didn't look chubby at all.\n",
    "\n",
    "I move to the right side of the chest, read what's on the hoodie, and it all clicks at once. The hoodie has the name of the local college on it. This is an adult, not a child. He's not wearing sweatpants, \\*she\\* is wearing yoga pants. She doesn't even know the couple that just came through.\n",
    "\n",
    "I look at her face, which is bright red, my hand is still on her boob, and I pull it back like I just got bit by a snake.\n",
    "\n",
    "I immediately call for my supervisor, who comes over and asks what's wrong, and I explain the situation to her.\n",
    "\n",
    "My supervisor covers her mouth, and at first I thought she was absolutely mortified, but then I realized she's trying not to laugh.\n",
    "\n",
    "She takes a minute to pull herself together, tells me to go take a break, and finishes screening the passenger herself.\n",
    "\n",
    "Once that was done, I apologize to the passenger, she tells me it's fine, that it wasn't the first time she was mistaken for a boy, and she probably should have said something before I started touching her. I leave her alone, and go talk to my supervisor to figure out exactly how fired I am.\n",
    "\n",
    "She tells me to calm down, that it was just an honest mistake, and that she has my back if the passenger files an official complaint, but that probably won't happen, and I shouldn't be worried.\n",
    "\n",
    "That reassured me a little, but I still groped a woman and ruined Christmas, so I feel like an absolute monster.\n",
    "\n",
    "I swallow my shame, and finish my shift, then I go into the airport proper to find some food, because I just finished a twelve hour shift and there's no way I have the energy to cook dinner.\n",
    "\n",
    "I saw my hapless victim sitting at her gate, waiting for her flight. I went up to her to apologize again, and saw that the flight had been delayed until morning (it was about eleven at night).\n",
    "\n",
    "I apologize again, she says it's fine, and I ask her if she's planning to stay the whole night. She says she has to, all the hotels in the area are book.\n",
    "\n",
    "I tell her that I'm getting some dinner, and offer to get her some food as well. After all, I already got to second base, I think it's only fair that I buy her dinner.\n",
    "\n",
    "She agrees, and we go to one of the restaurants that is open late, get some food, and start eating.\n",
    "\n",
    "She said she gets mistaken for a boy a lot, and it's not a big deal. I told her about how I had long hair and no beard in college, and at the gym people would frequently walk into the men's bathroom, see me, and do a double take to make sure they didn't walk into the ladies' room.\n",
    "\n",
    "She laughed, and we ended up talking for a few hours, before I finally told her that I had to get home, and apologized again for the accidental molestation.\n",
    "\n",
    "She said that all is forgiven, if I promise to take her on a real date when she gets back.\n",
    "\n",
    "I agreed, she gave me her phone number, and I went home, and immediately started texting her. We kept talking until her flight finally left, and when she got back I picked her up at the airport, and a few days later took her on that date that I promised her.\n",
    "\n",
    "We just celebrated our one year anniversary.\n",
    "\n",
    "She has long hair now.\n",
    "\n",
    "&#x200B;\n",
    "\n",
    "tl;dr: Thought an adult woman was a teenage boy, touched her on the boob, everything worked out better than expected.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "        model=model, contents=prompt_temp\n",
    "    )\n",
    "print(response)  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
