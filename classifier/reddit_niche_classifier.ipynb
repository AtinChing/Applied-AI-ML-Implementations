{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67769b",
   "metadata": {},
   "source": [
    "Proper about me can be made later\n",
    "Classifier that classifies what niche category a certain reddit post falls into.\n",
    "\n",
    "First, we need to collect data.\n",
    "There aren't many very good datasets, so we need to create our own.\n",
    "This will be done through data scraping via PRAW and weak supervision via a chosen LLM (I am using Gemini for this).\n",
    "\n",
    "First, scraping data via PRAW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773d9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\python312\\lib\\site-packages (from -r requirements.txt (line 1)) (7.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\atin5\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
      "Collecting google-genai (from -r requirements.txt (line 3))\n",
      "  Using cached google_genai-1.11.0-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\python312\\lib\\site-packages (from praw->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\python312\\lib\\site-packages (from praw->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\python312\\lib\\site-packages (from praw->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\atin5\\appdata\\roaming\\python\\python312\\site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\python312\\lib\\site-packages (from google-genai->-r requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\python312\\lib\\site-packages (from google-genai->-r requirements.txt (line 3)) (2.32.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\python312\\lib\\site-packages (from google-genai->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\python312\\lib\\site-packages (from google-genai->-r requirements.txt (line 3)) (2.11.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\python312\\lib\\site-packages (from google-genai->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\python312\\lib\\site-packages (from google-genai->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\python312\\lib\\site-packages (from google-genai->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python312\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python312\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 3)) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python312\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python312\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 3)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 3)) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai->-r requirements.txt (line 3)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\atin5\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 3)) (0.6.0)\n",
      "Using cached google_genai-1.11.0-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: google-genai\n",
      "Successfully installed google-genai-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install all required dependencies\n",
    "\n",
    "%pip install -r requirements.txt --user # --user flag is needed because one of the dependencies (google-genai) needs to access a script that is hidden in non-administrator environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f954a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your necessary imports\n",
    "import praw\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c71a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.1 of praw is outdated. Version 7.8.1 was released Friday October 25, 2024.\n"
     ]
    }
   ],
   "source": [
    "# Initialize reddit client session\n",
    "\n",
    "CLIENT_ID = \"0xeiOSktNDiHBw\"\n",
    "CLIENT_SECRET = \"c-bNB_P5wRjHZmaD1eaJnx0D3mlr8Q\"\n",
    "USER_AGENT = \"sestee 1.0\"\n",
    "cli = praw.Reddit(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        user_agent=USER_AGENT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98feecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a way for you to scrape posts from a subreddit of your choice.\n",
    "def scrape_popular_posts(subreddits, limit=100, sort_by=\"top\"):\n",
    "    posts = []\n",
    "\n",
    "    for sub_name in subreddits:\n",
    "        subreddit = cli.subreddit(sub_name)\n",
    "\n",
    "        if sort_by == \"top\":\n",
    "            submissions = subreddit.top(limit=limit)\n",
    "        elif sort_by == \"hot\":\n",
    "            submissions = subreddit.hot(limit=limit)\n",
    "        elif sort_by == \"new\":\n",
    "            submissions = subreddit.new(limit=limit)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid sort_by value. Use 'top', 'hot', or 'new'.\")\n",
    "\n",
    "        for post in submissions:\n",
    "            post_data = {\n",
    "                \"title\": post.title,\n",
    "                \"selftext\": post.selftext,\n",
    "                \"subreddit\": post.subreddit.display_name,\n",
    "                \"flair\": post.link_flair_text,\n",
    "                \"score\": post.score,\n",
    "                \"num_comments\": post.num_comments,\n",
    "                \"upvote_ratio\": post.upvote_ratio,\n",
    "                \"created_utc\": post.created_utc,\n",
    "                \"id\": post.id,\n",
    "                \"url\": post.url\n",
    "            }\n",
    "            posts.append(post_data)\n",
    "\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb67e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>flair</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>222000</td>\n",
       "      <td>7925</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.546377e+09</td>\n",
       "      <td>ablzuq</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How would you feel about Reddit adding 3 NSFW ...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>217930</td>\n",
       "      <td>2886</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.611860e+09</td>\n",
       "      <td>l7530r</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/l7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Would you watch a show where a billionaire CEO...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>197604</td>\n",
       "      <td>13327</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.581069e+09</td>\n",
       "      <td>f08dxb</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/f0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What if God came down one day and said \"It's p...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>195917</td>\n",
       "      <td>10227</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.600611e+09</td>\n",
       "      <td>iwedc5</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/iw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How would you feel about a feature where if so...</td>\n",
       "      <td></td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>None</td>\n",
       "      <td>186434</td>\n",
       "      <td>2772</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.572833e+09</td>\n",
       "      <td>draola</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title selftext  subreddit  \\\n",
       "0  People who haven't pooped in 2019 yet, why are...           AskReddit   \n",
       "1  How would you feel about Reddit adding 3 NSFW ...           AskReddit   \n",
       "2  Would you watch a show where a billionaire CEO...           AskReddit   \n",
       "3  What if God came down one day and said \"It's p...           AskReddit   \n",
       "4  How would you feel about a feature where if so...           AskReddit   \n",
       "\n",
       "  flair   score  num_comments  upvote_ratio   created_utc      id  \\\n",
       "0  None  222000          7925          0.91  1.546377e+09  ablzuq   \n",
       "1  None  217930          2886          0.87  1.611860e+09  l7530r   \n",
       "2  None  197604         13327          0.90  1.581069e+09  f08dxb   \n",
       "3  None  195917         10227          0.92  1.600611e+09  iwedc5   \n",
       "4  None  186434          2772          0.90  1.572833e+09  draola   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.reddit.com/r/AskReddit/comments/ab...  \n",
       "1  https://www.reddit.com/r/AskReddit/comments/l7...  \n",
       "2  https://www.reddit.com/r/AskReddit/comments/f0...  \n",
       "3  https://www.reddit.com/r/AskReddit/comments/iw...  \n",
       "4  https://www.reddit.com/r/AskReddit/comments/dr...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure out what subreddits you want to scrape from\n",
    "subreddits = [\"AskReddit\", \"relationships\", \"AmItheAsshole\", \"TrueOffMyChest\", \"TIFU\"]\n",
    "# Scrape the data from the subreddits\n",
    "data = scrape_popular_posts(subreddits, limit=50, sort_by=\"top\")\n",
    "# Save the data in a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Can save the dataframe to a CSV file too!\n",
    "#df.to_csv(\"reddit_posts.csv\", index=False)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406ef9f",
   "metadata": {},
   "source": [
    "Now we have a good chunk of all the data that we need. We need to clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d50082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data\n",
    "# Check and do later\n",
    "#df = df.dropna(subset=[\"selftext\", \"title\"])  # Drop rows with NaN in 'selftext' or 'title'\n",
    "#df = df[df[\"selftext\"].str.strip() != \"\"]  # Drop empty 'selftext' rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e90be",
   "metadata": {},
   "source": [
    "Now that we have our data, we will create a pipeline that allows us to label all the data entries and add a \"niche\" column via weak supervision. All entries will then be classified.\n",
    "These are the post classification categories we are planning to classify our posts into.\n",
    "\n",
    "| Label         | Description                                |\n",
    "|---------------|--------------------------------------------|\n",
    "| `advice`      | Help-seeking posts, questions, dilemmas    |\n",
    "| `story`       | Personal anecdotes with a beginning, middle, end |\n",
    "| `drama`       | High-stakes conflict, betrayal, gossip      |\n",
    "| `rant`        | Emotional venting or unfiltered frustration |\n",
    "| `humor`       | Meme-like, comedic, shitpost-style content  |\n",
    "| `informative` | Tips, how-tos, PSAs, educational content    |\n",
    "| `confession`  | Vulnerable personal reveals or identity-based confessions |\n",
    "| `unknown`     | Doesnâ€™t fit confidently into other categories|\n",
    "\n",
    "Note: We can use the `unknown` category to find the biggest weaknesses of our LLM, and we can then possibly fine-tune our LLM later very efficiently by especially targetting its weaknesses that we've detected here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd1549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Google GenAI API client\n",
    "client = genai.Client(api_key=\"AIzaSyDSyIBzIJ9yVnXYd6sJaE7oZ0Vqnc4kEPM\")\n",
    "model = \"gemini-2.0-flash\" # There are a LOT of models to choose from. But in my experience, I feel comfortable with AND use 2.0-flash the most. Will look into 2.5 series once they go through stable release.\n",
    "contents = \"\"\"I want to train a transofmer-based classifer that takes in the text of a reddit post and then classifes them into labels [personal advice, story, drama]. I only have a partial dataset for this. Can you help fill the rest for me?\n",
    "It should JUST classify the post into one niche category. Make me 75 rows in this dataset with equal category distribution. Do not stop until you are done\"\"\"\n",
    "response = client.models.generate_content(\n",
    "    model=model, contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
