{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are LLMs?\n",
    "LLMs (Large Language Models) are a powerful subset of NLP models characterized by their massive size, extensive training data, and ability to perform a wide range of language tasks with minimal task-specific training. Models like the Llama, GPT, or Claude series are examples of LLMs that have revolutionized what’s possible in NLP.\n",
    "- **I HIGHLY suggest going through the NLP part of this repository before going through this notebook.**\n",
    "In recent years, the field of NLP has been revolutionized by Large Language Models (LLMs). These models, which include architectures like GPT (Generative Pre-trained Transformer) and Llama, have transformed what’s possible in language processing.\n",
    "\n",
    "- LLMs are characterized by:\n",
    "\n",
    "    - Scale: They contain millions, billions, or even hundreds of billions of parameters\n",
    "    - General capabilities: They can perform multiple tasks without task-specific training\n",
    "    - In-context learning: They can learn from examples provided in the prompt\n",
    "    - Emergent abilities: As these models grow in size, they demonstrate capabilities that weren’t explicitly programmed or anticipated\n",
    "\n",
    "- LLMs also have important limitations:\n",
    "\n",
    "    - Hallucinations: They can generate incorrect information confidently\n",
    "    - Lack of true understanding: They lack true understanding of the world and operate purely on statistical patterns\n",
    "    - Bias: They may reproduce biases present in their training data or inputs.\n",
    "    - Context windows: They have limited context windows (though this is improving)\n",
    "    - Computational resources: They require significant computational resources\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
